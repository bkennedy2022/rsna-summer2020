{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer Neural Network\n",
    "##### This NN has one linear neuron and is trained to triple an input number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "Import everything we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "#### Define a single linear neuron.\n",
    "This doesn't have an activation function. Normally, would use a sigmoid activation function, maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1) # 1 input, 1 output\n",
    "        \n",
    "        # if you want more layers:\n",
    "        # self.fc1 = nn.Linear(1,10) # 1 input, 10 outputs\n",
    "        # self.fc2 = nn.Linear(10,1) # 10 inputs, 1 output\n",
    "        \n",
    "        #if you want to use relu:\n",
    "        #self.fc1 = nn.Linear(1,1)\n",
    "        #self.fc2 = nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "            \n",
    "        # x = self.fc2(self.fc1(x))\n",
    "        \n",
    "        # x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.1101]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7248], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "# if you want to use a GPU:\n",
    "# net = net.cuda()\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "#### Chuck a variable through our network:\n",
    "Create a random int variable to input. Setting requires_grad=True means it's optimizable (the network can optimize it as it learns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3242]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,1), requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it through our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6891]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def criterion(out, label):\n",
    "    return (label - out)**2 # loss function here is least squares\n",
    "# criterion = nn.MSELoss() #relu\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "#### Training\n",
    "Training set: we're trying to teach it to triple a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,3), (2,6), (3,9), (4,12), (5,15), (6,18)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 13.066350936889648\n",
      "Epoch 10 - loss: 0.012678511440753937\n",
      "Epoch 20 - loss: 0.004435475915670395\n",
      "Epoch 30 - loss: 0.001550470944494009\n",
      "Epoch 40 - loss: 0.0005419873050414026\n",
      "Epoch 50 - loss: 0.0001894647575682029\n",
      "Epoch 60 - loss: 6.622997170779854e-05\n",
      "Epoch 70 - loss: 2.3153070287662558e-05\n",
      "Epoch 80 - loss: 8.092946700344328e-06\n",
      "Epoch 90 - loss: 2.8276649572944734e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for i, data2 in enumerate(data):\n",
    "        X, Y = iter(data2)\n",
    "        X, Y = Variable(torch.FloatTensor([X]), requires_grad=True), Variable(torch.FloatTensor([Y]), requires_grad=False)\n",
    "      # if you wannt to use a GPU:\n",
    "        #X, Y = Variable(torch.FloatTensor([X]), requires_grad=True).cuda(), Variable(torch.FloatTensor([Y])).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if ((epoch % 10 == 0) and (i % 10 == 0)):\n",
    "            print(\"Epoch {} - loss: {}\".format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of Ax+b should be A = 3, b = 0. This is what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.9998]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0012], requires_grad=True)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0006]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(net(Variable(torch.Tensor([[3]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
