{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "Import some stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nbimporter\n",
    "#from wrangling import prep_dataframe\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import math\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataframe(directory, csv):   \n",
    "    diagnoses = pd.read_csv(csv)\n",
    "    diagnoses = diagnoses.to_numpy()\n",
    "    more = np.empty((len(diagnoses), 3), dtype = 'U18')\n",
    "    for x in range(len(diagnoses)):\n",
    "        more[x][0] = diagnoses[x][0][3:12]\n",
    "        more[x][1] = diagnoses[x][0][13:]\n",
    "\n",
    "    more[:,2] = diagnoses[:,1]\n",
    "\n",
    "    #test_list = os.listdir(directory)\n",
    "    test_list = glob.glob(\"/Users/brookskennedy/Desktop/stage_2_train/*.dcm\")[0:100]\n",
    "    #print(test_list)\n",
    "    image_arrays = np.zeros([512, 512])\n",
    "    df = pd.DataFrame(columns = [\"Image\", \"ID\", \"Diagnoses\"])\n",
    "\n",
    "    for file in test_list:\n",
    "        if(file != \".DS_Store\"):\n",
    "            try:\n",
    "                dataset = pydicom.dcmread(file, force = True)\n",
    "                diagnoses = more[:,1:][more[:,0]==file[44:53]]\n",
    "                filtered_diagnoses = diagnoses[:,0][diagnoses[:,1]=='1']\n",
    "                if filtered_diagnoses.size != 0:\n",
    "                    df = df.append({\"Image\": dataset.pixel_array, \"ID\": file[44:53], \n",
    "                                    \"Diagnoses\": filtered_diagnoses}, ignore_index = True)\n",
    "            except:\n",
    "                print(\"Error with file \"+file)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "Get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ = prep_dataframe(\"/Users/brookskennedy/Desktop/stage_2_train\", \"/Users/brookskennedy/Desktop/rsna/stage_2_train.csv\")\n",
    "#train_data_ = prep_dataframe(\"/home/wustl/brooks.kennedy/stage_2_train\", \"/home/wustl/brooks.kennedy/stage_2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Image, ID, Diagnoses]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = train_data_['Hemmorhage']\n",
    "train_x = train_data_['Image']\n",
    "ids = train_data_['ID']\n",
    "\n",
    "#convert training images, target data, ids to numpy arrays\n",
    "train_x = train_x.to_numpy()\n",
    "#train_y = train_y.to_numpy()\n",
    "ids = ids.to_numpy()\n",
    "for x in range(0, len(train_x)): #filter out incorrectly shaped images\n",
    "    if (train_x[x].shape != (512, 512)):\n",
    "        train_x = np.delete(train_x, x)\n",
    "        #train_y = np.delete(train_y, x)\n",
    "        ids = np.delete(ids, x)\n",
    "train_x = np.array([np.array(x) for x in train_x])\n",
    "\n",
    "#convert training images to pytorch tensors\n",
    "train_x = train_x.reshape(len(train_x), 1, 512, 512)\n",
    "train_x = train_x.astype('float')\n",
    "train_x = torch.from_numpy(train_x)\n",
    "\n",
    "# #convert target data to pytorch tensor\n",
    "# train_y = train_y.astype('bool')\n",
    "# train_y = torch.from_numpy(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "Display some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-83213ec095ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stage_2_train/ID_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".dcm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "for img in range (0,10):\n",
    "    dataset = pydicom.dcmread(\"stage_2_train/ID_\"+train_data['ID'][img]+\".dcm\")\n",
    "    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pydicom.dcmread(\"stage_2_train/ID_\"+train_data['ID'][img]+\".dcm\")\n",
    "plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "Define the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()   \n",
    "        self.ngpu = ngpu\n",
    "#         self.cnn_layers = Sequential(\n",
    "#             #convolution layer 1\n",
    "#             Conv2d(16, 4, kernel_size = 3, stride=1, padding=1),\n",
    "#             BatchNorm2d(4),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size = 2, stride=2),\n",
    "            \n",
    "#             #convolution layer 2\n",
    "#             Conv2d(4, 16, kernel_size = 3, stride=1, padding=1),\n",
    "#             BatchNorm2d(16),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size = 2, stride=2),\n",
    "#         )\n",
    "        self.dense_layer = Sequential (\n",
    "            nn.Linear(16, 128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Linear(256, 262144)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.cnn_layers(x)\n",
    "        #x = self.cnn_layers(x)\n",
    "        #torch.reshape(x, (4, 4))\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.reshape(x, (512, 512))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "Generate some random noise from a normal distribution with the mean and standard deviation of the original dataset and put it through the generator to produce an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "normal_ expects std > 0.0, but found std=nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-805c1ac5f85e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: normal_ expects std > 0.0, but found std=nan"
     ]
    }
   ],
   "source": [
    "gen = Generator(ngpu)\n",
    "mu = train_x.mean()\n",
    "std = train_x.std()\n",
    "noise = torch.normal(mu, std, size=(1,16))\n",
    "generated_image = gen(noise)\n",
    "\n",
    "#display the image\n",
    "generated_image=generated_image.detach().numpy() \n",
    "plt.imshow(  generated_image)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "def makeFakeData(generator, count, real_data):\n",
    "    mu = real_data.mean()\n",
    "    std = real_data.std()\n",
    "    generated_images = torch.empty(size=(count,1,512,512))\n",
    "    for i in range(count):\n",
    "        noise = torch.normal(mu, std, size=(1,16))\n",
    "        generated_image = gen(noise)\n",
    "        generated_image = generated_image.reshape((1,1,512,512))\n",
    "        generated_images[i] = generated_image #torch.cat((generated_images, generated_image), 0)\n",
    "    return generated_images\n",
    "\n",
    "gen = Generator(ngpu)\n",
    "ims = makeFakeData(gen, 5, train_x)\n",
    "#plt.imshow(ims[0].detach().numpy() )\n",
    "print(ims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "Define the discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "im_size = 512\n",
    "noise_size = 16\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(channels, im_size, 4, 2, 1, bias = False),\n",
    "            #BatchNorm2d(im_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(im_size, im_size*2, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(im_size*2, im_size*4, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(im_size*4, im_size*8, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(im_size*8, 1, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "#         self.linear_layers = Sequential(\n",
    "#             Linear(256*256, 10)\n",
    "#         )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator()\n",
    "ims.shape\n",
    "discrim = dis(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5248]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "Define loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, using BCE loss and Adam as the optimizer. look into these more later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "Now train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 500):\n",
    "    #input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # run on the GPU, or not\n",
    "#     if torch.cuda.is_available():\n",
    "#         #device1 = torch.device(\"cuda\")\n",
    "#         device1 = torch.device(0)\n",
    "#         print(\"Running on the GPU\")\n",
    "#     else:\n",
    "#         device1 = torch.device(\"cpu\")\n",
    "#         device2 = torch.device(\"cpu\")\n",
    "#         print(\"Running on the CPU\")\n",
    "    \n",
    "    device1 = torch.device(\"cuda\")\n",
    "    \n",
    "    # Models\n",
    "#     generator = Generator().to(device1)\n",
    "    generator = Generator(1).cuda(0)\n",
    "    discriminator = Discriminator().to(device1)\n",
    "\n",
    "    # Optimizers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "    # loss\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "        \n",
    "        # GENERATE FAKE DATA FROM RANDOM NOISE\n",
    "        generated_data = makeFakeData(generator, 100, train_x)\n",
    "\n",
    "        # real data\n",
    "        #true_labels, true_data = train_y[0:100], train_x[0:100]\n",
    "        true_data = train_x[0:100]\n",
    "        true_labels = [1.0]*100\n",
    "        true_labels = torch.tensor(true_labels).float()[0:100]\n",
    "        true_data = torch.tensor(true_data).float()[0:100]\n",
    "\n",
    "        # Train the generator\n",
    "        # We invert the labels here and don't train the discriminator because we want the generator\n",
    "        # to make things the discriminator classifies as true.\n",
    "        # PREDICTIONS OF THE DISCRIMINATOR ON THE FAKE DATA\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels) #USE TRUE LABELS \n",
    "        # BACKPROPOGATE ERROR THROUGH JUST THE GENERATOR\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size))\n",
    "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        if (i % 50 == 0):\n",
    "            #print(\"Step \"+str(i)+\": \")\n",
    "            print(list(map(int, torch.round(generated_data).tolist())))\n",
    "            #print(int(\"\".join(str(i) for i in torch.round(generated_data).tolist()),2))\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f4896947d693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-afbb685d43df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(max_int, batch_size, training_steps)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     generator = Generator().to(device1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "gen = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GRID V100S-16C'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just for the presentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "im_size = 512\n",
    "noise_size = 16\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):     \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cnn_layers = Sequential(\n",
    "            nn.Conv2d(channels, im_size, 4, 2, 1, bias = False),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(im_size, im_size*2, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(im_size*2, im_size*4, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "        \n",
    "            nn.Conv2d(im_size*4, im_size*8, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(im_size*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "     \n",
    "            nn.Conv2d(im_size*8, 1, 4, 2, 1),\n",
    "            nn.BatchNorm2d(im_size*16);\n",
    "            nn.ReLU(inplace=True)           \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
