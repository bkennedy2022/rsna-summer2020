{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "#from wrangling import prep_dataframe\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import math\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.cuda\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataframe(directory, csv):   \n",
    "    diagnoses = pd.read_csv(csv)\n",
    "    diagnoses = diagnoses.to_numpy()\n",
    "    more = np.empty((len(diagnoses), 3), dtype = 'U18')\n",
    "    for x in range(len(diagnoses)):\n",
    "        more[x][0] = diagnoses[x][0][3:12]\n",
    "        more[x][1] = diagnoses[x][0][13:]\n",
    "\n",
    "    more[:,2] = diagnoses[:,1]\n",
    "\n",
    "    #test_list = os.listdir(directory)\n",
    "    test_list = glob.glob(\"/home/wustl/brooks.kennedy/stage_2_train/*.dcm\")[0:100]\n",
    "    #print(test_list)\n",
    "    image_arrays = np.zeros([512, 512])\n",
    "    df = pd.DataFrame(columns = [\"Image\", \"ID\", \"Diagnoses\"])\n",
    "\n",
    "    for file in test_list:\n",
    "        if(file != \".DS_Store\"):\n",
    "            try:\n",
    "                #print(\"Success with file \" + file)\n",
    "                dataset = pydicom.dcmread(file, force = True)\n",
    "                diagnoses = more[:,1:][more[:,0]==file[44:53]]\n",
    "                filtered_diagnoses = diagnoses[:,0][diagnoses[:,1]=='1']\n",
    "#                any_diagnosis = filtered_diagnoses.size != 0\n",
    "#                 df = df.append({\"Image\": dataset.pixel_array, \"ID\": file[44:53], \n",
    "#                                 \"Diagnoses\": filtered_diagnoses, \n",
    "#                                \"Hemmorhage\": any_diagnosis}, ignore_index = True)\n",
    "                if filtered_diagnoses.size != 0:\n",
    "                    df = df.append({\"Image\": dataset.pixel_array, \"ID\": file[44:53], \n",
    "                                 \"Diagnoses\": filtered_diagnoses}, ignore_index = True)\n",
    "            except:\n",
    "                print(\"Error with file \"+file)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-1024, -1024, -1024, -1024, -1024, -1024, -1...</td>\n",
       "      <td>a799d9ece</td>\n",
       "      <td>[intraventricular, subarachnoid, subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-1024, -1024, -1024, -1024, -1024, -1024, -1...</td>\n",
       "      <td>a85fed3fc</td>\n",
       "      <td>[intraparenchymal, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-1024, -1024, -1024, -1024, -1024, -1024, -1...</td>\n",
       "      <td>b815b2f2f</td>\n",
       "      <td>[intraparenchymal, subarachnoid, subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>8b757e6ec</td>\n",
       "      <td>[intraparenchymal, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-2000, -2000, -2000, -2000, -2000, -2000, -2...</td>\n",
       "      <td>0d4ba7df6</td>\n",
       "      <td>[intraventricular, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[-2000, -2000, -2000, -2000, -2000, -2000, -2...</td>\n",
       "      <td>8434b7099</td>\n",
       "      <td>[subarachnoid, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>941750fca</td>\n",
       "      <td>[intraventricular, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[-1024, -1024, -1024, -1024, -1024, -1024, -1...</td>\n",
       "      <td>5a210b2bb</td>\n",
       "      <td>[subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[152, 152, 155, 159, 160, 158, 154, 154, 153,...</td>\n",
       "      <td>b72f6a4f4</td>\n",
       "      <td>[subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[-1024, -1024, -1024, -1024, -1024, -1024, -1...</td>\n",
       "      <td>56ef6e7d2</td>\n",
       "      <td>[subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e42baecaa</td>\n",
       "      <td>[subarachnoid, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[22, 24, 23, 22, 19, 16, 14, 18, 21, 22, 20, ...</td>\n",
       "      <td>f1f23d6bf</td>\n",
       "      <td>[intraventricular, subarachnoid, subdural, any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>6fb735628</td>\n",
       "      <td>[intraparenchymal, intraventricular, subarachn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[109, 111, 108, 108, 110, 112, 109, 107, 108,...</td>\n",
       "      <td>821106051</td>\n",
       "      <td>[subarachnoid, any]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Image         ID  \\\n",
       "0   [[-1024, -1024, -1024, -1024, -1024, -1024, -1...  a799d9ece   \n",
       "1   [[-1024, -1024, -1024, -1024, -1024, -1024, -1...  a85fed3fc   \n",
       "2   [[-1024, -1024, -1024, -1024, -1024, -1024, -1...  b815b2f2f   \n",
       "3   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  8b757e6ec   \n",
       "4   [[-2000, -2000, -2000, -2000, -2000, -2000, -2...  0d4ba7df6   \n",
       "5   [[-2000, -2000, -2000, -2000, -2000, -2000, -2...  8434b7099   \n",
       "6   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  941750fca   \n",
       "7   [[-1024, -1024, -1024, -1024, -1024, -1024, -1...  5a210b2bb   \n",
       "8   [[152, 152, 155, 159, 160, 158, 154, 154, 153,...  b72f6a4f4   \n",
       "9   [[-1024, -1024, -1024, -1024, -1024, -1024, -1...  56ef6e7d2   \n",
       "10  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  e42baecaa   \n",
       "11  [[22, 24, 23, 22, 19, 16, 14, 18, 21, 22, 20, ...  f1f23d6bf   \n",
       "12  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  6fb735628   \n",
       "13  [[109, 111, 108, 108, 110, 112, 109, 107, 108,...  821106051   \n",
       "\n",
       "                                            Diagnoses  \n",
       "0     [intraventricular, subarachnoid, subdural, any]  \n",
       "1                             [intraparenchymal, any]  \n",
       "2     [intraparenchymal, subarachnoid, subdural, any]  \n",
       "3                             [intraparenchymal, any]  \n",
       "4                             [intraventricular, any]  \n",
       "5                                 [subarachnoid, any]  \n",
       "6                             [intraventricular, any]  \n",
       "7                                     [subdural, any]  \n",
       "8                                     [subdural, any]  \n",
       "9                                     [subdural, any]  \n",
       "10                                [subarachnoid, any]  \n",
       "11    [intraventricular, subarachnoid, subdural, any]  \n",
       "12  [intraparenchymal, intraventricular, subarachn...  \n",
       "13                                [subarachnoid, any]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prep_dataframe(\"/home/wustl/brooks.kennedy/stage_2_train\", \"/home/wustl/brooks.kennedy/stage_2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hemmorhage_train_data = train_data.loc[train_data['Hemmorhage']==True]\n",
    "#train_y = hemmorhage_train_data['Hemmorhage']\n",
    "#train_x = hemmorhage_train_data['Image']\n",
    "#ids = hemmorhage_train_data['ID']\n",
    "train_y = train_data_['Hemmorhage']\n",
    "train_x = train_data_['Image']\n",
    "ids = train_data_['ID']\n",
    "\n",
    "#convert training images, target data, ids to numpy arrays\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "ids = ids.to_numpy()\n",
    "for x in range(0, 1000): #filter out incorrectly shaped images\n",
    "    if (train_x[x].shape != (512, 512)):\n",
    "        train_x = np.delete(train_x, x)\n",
    "        train_y = np.delete(train_y, x)\n",
    "        ids = np.delete(ids, x)\n",
    "train_x = np.array([np.array(x) for x in train_x])\n",
    "\n",
    "#convert training images to pytorch tensors\n",
    "train_x = train_x.reshape(1000, 1, 512, 512)\n",
    "train_x = train_x.astype('float')\n",
    "train_x = torch.from_numpy(train_x)\n",
    "\n",
    "#convert target data to pytorch tensor\n",
    "train_y = train_y.astype('bool')\n",
    "train_y = torch.from_numpy(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is non-convolutional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()       \n",
    "#         self.cnn_layers = Sequential(\n",
    "#             #convolution layer 1\n",
    "#             Conv2d(16, 4, kernel_size = 3, stride=1, padding=1),\n",
    "#             BatchNorm2d(4),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size = 2, stride=2),\n",
    "            \n",
    "#             #convolution layer 2\n",
    "#             Conv2d(4, 16, kernel_size = 3, stride=1, padding=1),\n",
    "#             BatchNorm2d(16),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size = 2, stride=2),\n",
    "#         )\n",
    "        self.dense_layer = Sequential (\n",
    "            nn.Linear(16, 128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Linear(256, 262144)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.cnn_layers(x)\n",
    "        #x = self.cnn_layers(x)\n",
    "        #torch.reshape(x, (4, 4))\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.reshape(x, (512, 512))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1 # would be 3 for a RGB image\n",
    "im_size = 512\n",
    "noise_size = 16\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(Generator, self)._init_()\n",
    "        self.layer = Sequential (\n",
    "            nn.Conv2d(noise_size, im_size*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(im_size*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(im_size*8, im_size*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(im_size*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(im_size*4, im_size*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(im_size*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(im_size*2, im_size, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(im_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(im_size, channels, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffe6f6e5d506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "mu = train_x.mean()\n",
    "std = train_x.std()\n",
    "noise = torch.normal(mu, std, size=(1,16))\n",
    "generated_image = gen(noise)\n",
    "\n",
    "#display the image\n",
    "generated_image=generated_image.detach().numpy() \n",
    "plt.imshow(  generated_image)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
